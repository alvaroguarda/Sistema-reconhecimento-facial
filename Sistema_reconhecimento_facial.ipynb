{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "https://github.com/alvaroguarda/Sistema-reconhecimento-facial/blob/main/Sistema_reconhecimento_facial.ipynb",
      "authorship_tag": "ABX9TyMJM05SFdT18Zdc9NJB8DZV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alvaroguarda/Sistema-reconhecimento-facial/blob/main/Sistema_reconhecimento_facial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install deepface\n",
        "!pip install opencv-python"
      ],
      "metadata": {
        "collapsed": true,
        "id": "YdGkkLCa-SkC",
        "outputId": "c7a084e8-cacd-4110-f431-c89a55a60ffd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting deepface\n",
            "  Downloading deepface-0.0.95-py3-none-any.whl.metadata (35 kB)\n",
            "Requirement already satisfied: requests>=2.27.1 in /usr/local/lib/python3.12/dist-packages (from deepface) (2.32.4)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.12/dist-packages (from deepface) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.23.4 in /usr/local/lib/python3.12/dist-packages (from deepface) (2.2.2)\n",
            "Requirement already satisfied: gdown>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from deepface) (5.2.0)\n",
            "Requirement already satisfied: tqdm>=4.30.0 in /usr/local/lib/python3.12/dist-packages (from deepface) (4.67.1)\n",
            "Requirement already satisfied: Pillow>=5.2.0 in /usr/local/lib/python3.12/dist-packages (from deepface) (11.3.0)\n",
            "Requirement already satisfied: opencv-python>=4.5.5.64 in /usr/local/lib/python3.12/dist-packages (from deepface) (4.12.0.88)\n",
            "Requirement already satisfied: tensorflow>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from deepface) (2.19.0)\n",
            "Requirement already satisfied: keras>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from deepface) (3.10.0)\n",
            "Requirement already satisfied: Flask>=1.1.2 in /usr/local/lib/python3.12/dist-packages (from deepface) (3.1.2)\n",
            "Collecting flask-cors>=4.0.1 (from deepface)\n",
            "  Downloading flask_cors-6.0.1-py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting mtcnn>=0.1.0 (from deepface)\n",
            "  Downloading mtcnn-1.0.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting retina-face>=0.0.14 (from deepface)\n",
            "  Downloading retina_face-0.0.17-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting fire>=0.4.0 (from deepface)\n",
            "  Downloading fire-0.7.1-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting gunicorn>=20.1.0 (from deepface)\n",
            "  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.12/dist-packages (from fire>=0.4.0->deepface) (3.1.0)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from Flask>=1.1.2->deepface) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.12/dist-packages (from Flask>=1.1.2->deepface) (8.3.0)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from Flask>=1.1.2->deepface) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.12/dist-packages (from Flask>=1.1.2->deepface) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from Flask>=1.1.2->deepface) (3.0.3)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from Flask>=1.1.2->deepface) (3.1.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from gdown>=3.10.1->deepface) (4.13.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from gdown>=3.10.1->deepface) (3.20.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gunicorn>=20.1.0->deepface) (25.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from keras>=2.2.0->deepface) (1.4.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=2.2.0->deepface) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=2.2.0->deepface) (0.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.12/dist-packages (from keras>=2.2.0->deepface) (3.14.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=2.2.0->deepface) (0.17.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.12/dist-packages (from keras>=2.2.0->deepface) (0.5.3)\n",
            "Requirement already satisfied: joblib>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from mtcnn>=0.1.0->deepface) (1.5.2)\n",
            "Collecting lz4>=4.3.3 (from mtcnn>=0.1.0->deepface)\n",
            "  Downloading lz4-4.4.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.23.4->deepface) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.23.4->deepface) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.23.4->deepface) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.27.1->deepface) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.27.1->deepface) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.27.1->deepface) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.27.1->deepface) (2025.10.5)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->deepface) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->deepface) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->deepface) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->deepface) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->deepface) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->deepface) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->deepface) (5.29.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->deepface) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->deepface) (1.17.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->deepface) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->deepface) (1.17.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->deepface) (1.75.1)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->deepface) (2.19.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow>=1.9.0->deepface) (0.45.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow>=1.9.0->deepface) (3.9)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow>=1.9.0->deepface) (0.7.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown>=3.10.1->deepface) (2.8)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown>=3.10.1->deepface) (1.7.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=2.2.0->deepface) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=2.2.0->deepface) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=2.2.0->deepface) (0.1.2)\n",
            "Downloading deepface-0.0.95-py3-none-any.whl (128 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m128.3/128.3 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fire-0.7.1-py3-none-any.whl (115 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m115.9/115.9 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading flask_cors-6.0.1-py3-none-any.whl (13 kB)\n",
            "Downloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mtcnn-1.0.0-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading retina_face-0.0.17-py3-none-any.whl (25 kB)\n",
            "Downloading lz4-4.4.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lz4, gunicorn, fire, mtcnn, flask-cors, retina-face, deepface\n",
            "Successfully installed deepface-0.0.95 fire-0.7.1 flask-cors-6.0.1 gunicorn-23.0.0 lz4-4.4.4 mtcnn-1.0.0 retina-face-0.0.17\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: numpy<2.3.0,>=2 in /usr/local/lib/python3.12/dist-packages (from opencv-python) (2.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from deepface import DeepFace\n",
        "import cv2\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "metadata": {
        "id": "QaZBTUAL-aYC",
        "outputId": "4e1208e8-be9d-4a72-d572-dcadf4ddd56e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25-10-15 22:25:31 - Directory /root/.deepface has been created\n",
            "25-10-15 22:25:31 - Directory /root/.deepface/weights has been created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = 'drive/MyDrive/FaceRecognition/images/teste_612x612.jpg'\n",
        "representation = DeepFace.represent(img_path=image_path, model_name='VGG-Face', enforce_detection=False)"
      ],
      "metadata": {
        "id": "Fbm6c3P5-44I",
        "outputId": "df0477cd-9cfd-46fa-8971-f8e8a6c9942a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25-10-15 22:32:44 - ğŸ”— vgg_face_weights.h5 will be downloaded from https://github.com/serengil/deepface_models/releases/download/v1.0/vgg_face_weights.h5 to /root/.deepface/weights/vgg_face_weights.h5...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://github.com/serengil/deepface_models/releases/download/v1.0/vgg_face_weights.h5\n",
            "To: /root/.deepface/weights/vgg_face_weights.h5\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 580M/580M [00:06<00:00, 87.0MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mtcnn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "fNi_vWrYcMMd",
        "outputId": "de122d78-d2b0-4f1d-c434-1a88f944a96c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mtcnn\n",
            "  Downloading mtcnn-1.0.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: joblib>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from mtcnn) (1.5.2)\n",
            "Collecting lz4>=4.3.3 (from mtcnn)\n",
            "  Downloading lz4-4.4.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Downloading mtcnn-1.0.0-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lz4-4.4.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lz4, mtcnn\n",
            "Successfully installed lz4-4.4.4 mtcnn-1.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "Syrw5zGPcnrF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from mtcnn.mtcnn import MTCNN\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Flatten, Dense\n",
        "from keras.src.legacy.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "g_fh_HIgb93W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Flatten, Dense\n",
        "from keras.src.legacy.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "TQiM_jzZerXe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "detector = MTCNN()"
      ],
      "metadata": {
        "id": "Ca1QQ5pabzNm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Display image\n",
        "def display(img, neww, frameName=\"Image\"):\n",
        "    h, w = img.shape[0:2]\n",
        "    newh = int(neww*(h/w))\n",
        "    img = cv2.resize(img, (neww, newh))\n",
        "    cv2.imshow(frameName, img)\n",
        "    cv2.waitKey(0)\n",
        "    cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "TDxUooonfkCD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to detect faces in an image\n",
        "def detect_faces(image_path):\n",
        "    \"\"\"\n",
        "    Detects faces in an image and draws rectangles around them.\n",
        "\n",
        "    Args:\n",
        "        image_path (str): Path to the image file.\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray or None: The image with rectangles drawn around faces,\n",
        "                                 or None if the image could not be read.\n",
        "        list: List of detected face coordinates. Element: [x, y, w, h].\n",
        "    \"\"\"\n",
        "    img = cv2.imread(image_path)\n",
        "\n",
        "    if img is None:\n",
        "        print(f\"Error: Could not read image file {image_path}\")\n",
        "        return None\n",
        "\n",
        "    # Detect faces in the image\n",
        "    faces_rect = detector.detect_faces(img)\n",
        "\n",
        "    return img, faces_rect"
      ],
      "metadata": {
        "id": "PO6Qp7Zubyc3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "def learn(data_path):\n",
        "    # Define image size, batch size, and other parameters\n",
        "    img_size = (224, 224)\n",
        "    batch_size = 32\n",
        "    num_classes = 4  # Number of classes in the dataset\n",
        "    epochs = 20\n",
        "    learning_rate = 0.0001\n",
        "    input_shape = (224, 224, 3)\n",
        "    validation_split = 0.2\n",
        "\n",
        "    # Load the VGG16 model without the top layers and with pre-trained weights\n",
        "    base_model = VGG16(weights='imagenet', include_top=False,\n",
        "                       input_shape=input_shape, pooling='max')\n",
        "    base_model.trainable = False  # Freeze the base model\n",
        "\n",
        "    # Create a new model and add layers\n",
        "    model = Sequential()\n",
        "    model.add(base_model)\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "    # Compile the model\n",
        "    optimizer = Adam(learning_rate=learning_rate)\n",
        "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Print the model summary\n",
        "    model.summary()\n",
        "\n",
        "    # Data augmentation and data generators\n",
        "    datagen = ImageDataGenerator(rescale=1./255, validation_split=validation_split)\n",
        "    train_generator = datagen.flow_from_directory(data_path, target_size=img_size, batch_size=batch_size, class_mode='sparse', subset='training')\n",
        "    validation_generator = datagen.flow_from_directory(data_path, target_size=img_size, batch_size=batch_size, class_mode='sparse', subset='validation')\n",
        "\n",
        "    class_name_list = list(train_generator.class_indices.keys())\n",
        "\n",
        "    # Train the model\n",
        "    history = model.fit(train_generator, epochs=epochs, validation_data=validation_generator)\n",
        "    # Save the trained model\n",
        "    model.save('VGG16_finetuned_model.h5')\n",
        "    print('Model trained and saved as vgg16_finetuned_model.h5')\n",
        "    return model, history, img_size, class_name_list\n"
      ],
      "metadata": {
        "id": "Q_Gh3AAvm3-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the learning history\n",
        "def plot_history(history):\n",
        "    # Plot training & validation accuracy values\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "    plt.title('Model accuracy')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "    # Plot training & validation loss values\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('Model loss')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "    plt.show()\n",
        "    return"
      ],
      "metadata": {
        "id": "-1xDykgKoTKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to preprocess and predict the class of a new image\n",
        "def predict_image(img, model, img_size):\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    img = cv2.resize(img, img_size)\n",
        "    img = img.astype('float32') / 255.0\n",
        "    img = np.expand_dims(img, axis=0)  # Add batch dimension\n",
        "    predictions = model.predict(img)\n",
        "    print(predictions)\n",
        "    predicted_class = np.argmax(predictions, axis=1)[0]\n",
        "    confidence = np.max(predictions)\n",
        "    return predicted_class, confidence"
      ],
      "metadata": {
        "id": "AEOi5gV0paR0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Call the learn function\n",
        "data_path = 'images/Cleaned Dataset'\n",
        "\n",
        "# Train the model\n",
        "model, history, img_size, class_name_list = learn(data_path)\n",
        "# Plot training history\n",
        "plot_history(history)"
      ],
      "metadata": {
        "id": "rGxTrLOVoAnA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage of the face detection function\n",
        "test_image_path = 'drive/MyDrive/FaceRecognition/images/teste_612x612.jpg'\n",
        "\n",
        "if os.path.exists(test_image_path):\n",
        "    img, faces_rect = detect_faces(test_image_path)\n",
        "\n",
        "    # Predict end draw rectangles around the detected faces\n",
        "    #for (x, y, w, h) in faces_rect:\n",
        "    for result in faces_rect:\n",
        "        x, y, w, h = result['box']\n",
        "        face_img = img[y:y+h, x:x+w]\n",
        "        predicted_class, confidence = predict_image(face_img, model, img_size)\n",
        "        confidence = int(confidence * 100)  # Convert to percentage\n",
        "        print(f'Predicted class: {class_name_list[predicted_class]}, Confidence: {confidence}', '%')\n",
        "\n",
        "        cv2.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 2) # Blue rectangle\n",
        "        # Add class label and confidence\n",
        "        label = f\"{class_name_list[predicted_class]}: {confidence}%\"\n",
        "        if confidence < 50:\n",
        "            label = f\"Unknown : {confidence}\"\n",
        "        cv2.putText(\n",
        "            img,\n",
        "            text=label,\n",
        "            org=(x, max(y-10, 0)),\n",
        "            fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
        "            fontScale=0.3,\n",
        "            color=(36, 255, 12),\n",
        "            thickness=1\n",
        "        )  # Green text\n",
        "\n",
        "    # Display the image with detected faces\n",
        "    display(img, 600, \"Detected Faces\")\n",
        "else:\n",
        "    print(f'Test image not found at {test_image_path}. Please provide a valid image path.')"
      ],
      "metadata": {
        "id": "ceRT0mzipQLm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#------------------------------------"
      ],
      "metadata": {
        "id": "wofMSTt_aZkL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_image(path):\n",
        "    try:\n",
        "        if os.path.getsize(path) > 0: # Check if file is not empty\n",
        "          img = image.load_img(path, target_size=(224, 224))\n",
        "          x = image.img_to_array(img)\n",
        "          x = np.expand_dims(x, axis=0)\n",
        "          x = preprocess_input(x)\n",
        "          return img, x\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading image {path}: {e}\")\n",
        "    return None, None"
      ],
      "metadata": {
        "id": "rlOHYSrxXrMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QUZnPEi2VmjL"
      },
      "outputs": [],
      "source": [
        "img_path = 'FaceRecognition/images/homem/frame_0000.jpg'\n",
        "\n",
        "img, x = get_image(img_path)\n",
        "\n",
        "# load image from file\n",
        "pixels = plt.imread(img_path)\n",
        "\n",
        "# create the detector, using default weights\n",
        "detector = MTCNN()\n",
        "# detect faces in the image\n",
        "results = detector.detect_faces(pixels)\n",
        "\n",
        "# # display faces on the original image\n",
        "# fig, ax = plt.subplots(figsize=(10, 10))\n",
        "# ax.imshow(pixels)\n",
        "# # plot each box\n",
        "# for result in results:\n",
        "#     x, y, width, height = result['box']\n",
        "#     # create the shape\n",
        "#     rect = patches.Rectangle((x, y), width, height, fill=False, color='red')\n",
        "#     ax.add_patch(rect)\n",
        "# plt.show()\n",
        "\n",
        "\n",
        "# extract the bounding box from the first face\n",
        "x1, y1, width, height = results[0]['box']\n",
        "x2, y2 = x1 + width, y1 + height\n",
        "\n",
        "# extract the face\n",
        "face = pixels[y1:y2, x1:x2]\n",
        "# resize pixels to the model size\n",
        "image = Image.fromarray(face)\n",
        "image = image.resize((224, 224))\n",
        "face_array = np.asarray(image)\n",
        "\n",
        "\n",
        "# extract a single face from a given photograph\n",
        "def extract_face(filename, required_size=(224, 224)):\n",
        "\t# load image from file\n",
        "    pixels = plt.imread(img_path)\n",
        "    # create the detector, using default weights\n",
        "    detector = MTCNN()\n",
        "\t# detect faces in the image\n",
        "    results = detector.detect_faces(pixels)\n",
        "\t# extract the bounding box from the first face\n",
        "    x1, y1, width, height = results[0]['box']\n",
        "    x2, y2 = x1 + width, y1 + height\n",
        "\t# extract the face\n",
        "    face = pixels[y1:y2, x1:x2]\n",
        "\t# resize pixels to the model size\n",
        "    image = Image.fromarray(face)\n",
        "    image = image.resize(required_size)\n",
        "    face_array = np.asarray(image)\n",
        "    return face_array\n",
        "\n",
        "# load the photo and extract the face\n",
        "pixels = extract_face(img_path)\n",
        "# convert one face into samples\n",
        "pixels = pixels.astype('float32')\n",
        "samples = expand_dims(pixels, axis=0)\n",
        "# prepare the face for the model, e.g. center pixels\n",
        "samples = preprocess_input(samples, version=2)\n",
        "# create a vggface model\n",
        "model = VGGFace(model='resnet50')\n",
        "# perform prediction\n",
        "yhat = model.predict(samples)\n",
        "# convert prediction into names\n",
        "results = decode_predictions(yhat)\n",
        "# display most likely results\n",
        "for result in results[0]:\n",
        "\tprint('%s: %.3f%%' % (result[0], result[1]*100))\n"
      ]
    }
  ]
}